{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load Libraries**"
      ],
      "metadata": {
        "id": "ltZ-ErlbcwsP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "URzjtOh6hwcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6e6b62-80bc-4a27-a8d0-08bddaf333f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.ml.feature import PCA, VectorAssembler,StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pyspark.sql.functions as f\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import sklearn.metrics\n",
        "from pyspark.ml.clustering import GaussianMixture\n",
        "from pyspark.ml.clustering import KMeans, KMeansModel\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import  LogisticRegression\n",
        "import re\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.regression import RandomForestRegressor,DecisionTreeRegressor\n",
        "from functools import reduce\n",
        "from pyspark.sql import SparkSession\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Manipulation**"
      ],
      "metadata": {
        "id": "xyCT3MWudURH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession\\\n",
        "    .builder.appName(\"MachineLearningTesting\")\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .getOrCreate()\n",
        "df_pyspark=spark.read.csv('churn.csv',header=True,inferSchema=True)\n",
        "\n",
        "oldcolumns=df_pyspark.columns\n",
        "newcolumns=pd.Series(df_pyspark.columns).str.lower().str.replace(' ','_').tolist()\n",
        "df_pyspark=reduce(lambda df,\n",
        "      i: df.withColumnRenamed(oldcolumns[i],newcolumns[i]),range(len(oldcolumns)),df_pyspark)\n",
        "mapping={'account_length':'account_len',\"int'l_plan\":'intl_plan','eve_mins':'evening_mins','eve_calls':'evening_calls',\n",
        "         'eve_charge': 'evening_charge', 'churn?':'churn'}\n",
        "\n",
        "newcol=[mapping.get(x,x) for x in df_pyspark.columns]\n",
        "df_pyspark.toDF(*newcol).toPandas()\n",
        "df_pyspark=df_pyspark.toDF(*newcol)\n",
        "\n",
        "# convert strings to upper and making any neccesary correction\n",
        "\n",
        "df_pyspark=df_pyspark.withColumn(\"churn\",f.regexp_replace(\"churn\",\"\\.\",\"\"))\n",
        "\n",
        "upperlist=[col[0] for col in df_pyspark.dtypes if col[1]=='string']\n",
        "\n",
        "df_pyspark=reduce(lambda df,colname:\n",
        "   df.withColumn(colname,f.upper(f.col(colname))),upperlist,df_pyspark)\n"
      ],
      "metadata": {
        "id": "LHJHgTUUqKf6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA**"
      ],
      "metadata": {
        "id": "qPMdGDzudSrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col=[item[0] for item in df_pyspark.dtypes if not(item[1].startswith('string'))]\n",
        "\n",
        "featureassembler=VectorAssembler(inputCols=col,outputCol='features')\n",
        "assembler_df=featureassembler.transform(df_pyspark)\n",
        "\n",
        "scaler=StandardScaler(inputCol='features',outputCol='features_scaled',withStd=True,withMean=False)\n",
        "scaled_df=scaler.fit(assembler_df).transform(assembler_df)\n",
        "\n",
        "pca=PCA(k=len(col),inputCol='features',outputCol='pca_features')\n",
        "model=pca.fit(scaled_df)\n",
        "\n",
        "print(model.explainedVariance.round(3)*100)\n",
        "print(model.explainedVariance.cumsum().round(3)*100)\n",
        "\n",
        "pca=PCA(k=4,inputCol='features',outputCol='pca_features')\n",
        "model=pca.fit(scaled_df)\n",
        "\n",
        "pca_df=model.transform(scaled_df)\n",
        "\n",
        "pca_df.select('pca_features').show(truncate=False)\n"
      ],
      "metadata": {
        "id": "gYzbg4em4dOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c107ac1-3100-4777-d1c6-327053c0d5de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23.5 20.1 19.6 13.9 12.2  3.1  3.1  2.9  1.4  0.1  0.   0.   0.   0.\n",
            "  0.   0. ]\n",
            "[ 23.5  43.7  63.3  77.1  89.3  92.4  95.5  98.4  99.9  99.9 100.  100.\n",
            " 100.  100.  100.  100. ]\n",
            "+-------------------------------------------------------------------------------+\n",
            "|pca_features                                                                   |\n",
            "+-------------------------------------------------------------------------------+\n",
            "|[-278.5709226981437,27.07709503672126,297.2297740248364,-404.50495418263625]   |\n",
            "|[-173.8461564451706,22.11452207304285,309.12035879832683,-405.0323256391566]   |\n",
            "|[-251.93720525128546,9.717034506165433,187.1094726516783,-403.08195917163334]  |\n",
            "|[-306.26069317050496,-59.265720530748446,181.35476455020364,-403.8758691875634]|\n",
            "|[-175.55925259576688,20.44659897036715,227.15102808832444,-408.1380434549122]  |\n",
            "|[-235.02778511191295,71.78089389732655,277.68974689091715,-498.8641288738459]  |\n",
            "|[-235.19597517888946,173.69741231275447,356.5419980946255,-497.0944537111983]  |\n",
            "|[-164.59029935871183,-30.447134861953813,221.12586096844967,-401.8129253289246]|\n",
            "|[-202.36534176843486,173.3827936043798,362.93450311671745,-395.3668424119971]  |\n",
            "|[-274.98919639833264,2.4248495063118867,378.722231048645,-404.0330652728015]   |\n",
            "|[-140.84489676015443,75.62900816514481,292.1016192035709,-407.87372114767004]  |\n",
            "|[-197.5961172440703,27.194719805235167,242.06379362242467,-407.9238634458065]  |\n",
            "|[-135.00949763290888,10.783373376421466,164.470516380805,-391.71590128454704]  |\n",
            "|[-167.7590283635875,102.44607043492717,286.52783623154073,-499.8383522282373]  |\n",
            "|[-135.0262956677803,145.55851504009388,331.43126524323645,-407.47277337136325] |\n",
            "|[-350.76386711069836,173.2946190147763,291.01681498794653,-400.55168435420313] |\n",
            "|[-208.492038645739,184.38704456749758,218.81257398046847,-397.3613060058193]   |\n",
            "|[-200.05694938390064,111.728912880884,216.6419454376756,-499.71583240181735]   |\n",
            "|[-198.9391541785873,88.1194264194746,244.1921044093815,-502.5128134825928]     |\n",
            "|[-233.85362432026028,25.734791642236246,235.7612435173622,-409.18412699330264] |\n",
            "+-------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_df=pca_df.withColumn('total_charge',\n",
        "                         sum([f.col(colname) for colname in df_pyspark.columns if '_charge' in colname]))\n",
        "\n",
        "df=pca_df.join(df_pyspark.groupBy('phone').pivot('state').agg(f.count('*')).fillna(0),\n",
        "             ['phone'],how='inner')\n",
        "state_cols=[x[0] for x in df_pyspark.select('state').distinct().collect()]\n",
        "\n",
        "listcol=['pca_features']\n",
        "listcol.extend(state_cols)\n",
        "\n",
        "featureassembler=VectorAssembler(inputCols=listcol,outputCol='final_features')\n",
        "df=featureassembler.transform(df)"
      ],
      "metadata": {
        "id": "qZBxc2UXAh1b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "svilh8ADeXUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data,test_data)= df.randomSplit([0.7,0.3])\n",
        "lm = LinearRegression(featuresCol='final_features', labelCol='total_charge')\n",
        "model = lm.fit(train_data)\n",
        "\n",
        "def modelsummary(model):\n",
        "    print(\"##\", \"-------------------------------------------------\")\n",
        "    print(\"##\", \"  Estimate  | Std.Error  | t-statistic  | p-value\")\n",
        "    coef = np.append(list(model.coefficients), model.intercept)\n",
        "    summary = model.summary  # Corrected this line\n",
        "\n",
        "    for i in range(len(summary.pValues)):  # Corrected this line\n",
        "        print(\"##\", '{:9.2f}'.format(coef[i]),\n",
        "              '{:12.2f}'.format(summary.coefficientStandardErrors[i]),  # Corrected this line\n",
        "              '{:12.2f}'.format(summary.tValues[i]),  # Corrected this line\n",
        "              '{:12.2f}'.format(summary.pValues[i]))  # Corrected this line\n",
        "\n",
        "    print(\"##\", '--------------')\n",
        "\n",
        "    print(\"##\", \"Mean squared error: %.5f\" % summary.meanSquaredError,\n",
        "          \"RMSE: %1.5f\" % summary.rootMeanSquaredError)\n",
        "    print(\"##\", 'Multiple R-squared: %1.5f' % summary.r2)\n",
        "\n",
        "modelsummary(model)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select('features', 'total_charge', 'prediction')\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "evaluator = RegressionEvaluator(labelCol='total_charge',\n",
        "                                predictionCol=\"prediction\",\n",
        "                                metricName='rmse')\n",
        "\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUekAA09odt0",
        "outputId": "abd283dc-0b0c-4c18-8db9-b0a17aff2375"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## -------------------------------------------------\n",
            "##   Estimate  | Std.Error  | t-statistic  | p-value\n",
            "##     -0.17         0.00      -595.49         0.00\n",
            "##      0.04         0.00       134.64         0.00\n",
            "##      0.08         0.00       248.74         0.00\n",
            "##     -0.00         0.00        -5.77         0.00\n",
            "##   1339.45   1478342.00         0.00         1.00\n",
            "##   1339.34   1478342.00         0.00         1.00\n",
            "##   1339.16   1478342.00         0.00         1.00\n",
            "##   1339.46   1478342.00         0.00         1.00\n",
            "##   1339.45   1478342.00         0.00         1.00\n",
            "##   1339.35   1478342.00         0.00         1.00\n",
            "##   1339.30   1478342.00         0.00         1.00\n",
            "##   1339.46   1478342.00         0.00         1.00\n",
            "##   1339.22   1478342.00         0.00         1.00\n",
            "##   1339.36   1478342.00         0.00         1.00\n",
            "##   1339.49   1478342.00         0.00         1.00\n",
            "##   1339.29   1478342.00         0.00         1.00\n",
            "##   1339.32   1478342.00         0.00         1.00\n",
            "##   1339.24   1478342.00         0.00         1.00\n",
            "##   1339.09   1478342.00         0.00         1.00\n",
            "##   1339.31   1478342.00         0.00         1.00\n",
            "##   1339.33   1478342.00         0.00         1.00\n",
            "##   1339.32   1478342.00         0.00         1.00\n",
            "##   1339.24   1478342.00         0.00         1.00\n",
            "##   1339.36   1478342.00         0.00         1.00\n",
            "##   1339.29   1478342.00         0.00         1.00\n",
            "##   1339.28   1478342.00         0.00         1.00\n",
            "##   1339.46   1478342.00         0.00         1.00\n",
            "##   1339.33   1478342.00         0.00         1.00\n",
            "##   1339.22   1478342.00         0.00         1.00\n",
            "##   1339.37   1478342.00         0.00         1.00\n",
            "##   1339.28   1478342.00         0.00         1.00\n",
            "##   1339.11   1478342.00         0.00         1.00\n",
            "##   1339.12   1478342.00         0.00         1.00\n",
            "##   1339.42   1478342.00         0.00         1.00\n",
            "##   1339.34   1478342.00         0.00         1.00\n",
            "##   1339.30   1478342.00         0.00         1.00\n",
            "##   1339.29   1478342.00         0.00         1.00\n",
            "##   1339.35   1478342.00         0.00         1.00\n",
            "##   1339.13   1478342.00         0.00         1.00\n",
            "##   1339.40   1478342.00         0.00         1.00\n",
            "##   1339.31   1478342.00         0.00         1.00\n",
            "##   1339.31   1478342.00         0.00         1.00\n",
            "##   1339.21   1478342.00         0.00         1.00\n",
            "##   1339.32   1478342.00         0.00         1.00\n",
            "##   1339.25   1478342.00         0.00         1.00\n",
            "##   1339.28   1478342.00         0.00         1.00\n",
            "##   1339.35   1478342.00         0.00         1.00\n",
            "##   1339.53   1478342.00         0.00         1.00\n",
            "##   1339.31   1478342.00         0.00         1.00\n",
            "##   1339.19   1478342.00         0.00         1.00\n",
            "##   1339.25   1478342.00         0.00         1.00\n",
            "##   1339.31   1478342.00         0.00         1.00\n",
            "##   1339.35   1478342.00         0.00         1.00\n",
            "##   1339.48   1478342.00         0.00         1.00\n",
            "##   1339.21   1478342.00         0.00         1.00\n",
            "##  -1336.48   1478342.00        -0.00         1.00\n",
            "## --------------\n",
            "## Mean squared error: 0.55467 RMSE: 0.74476\n",
            "## Multiple R-squared: 0.99491\n",
            "Root Mean Squared Error (RMSE): 0.772739279688758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DecisionTreeRegressor**"
      ],
      "metadata": {
        "id": "wu-fQlrQkqEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listcol=[col for col in df_pyspark.columns if '_charge' in col]\n",
        "df_pyspark=df_pyspark.withColumn('total_charge',sum([f.col(colname) for colname in listcol]))\n",
        "\n",
        "listcol=[x for x in df_pyspark.columns if re.compile('^.*_calls|mins$').search(x)]\n",
        "featureassembler=VectorAssembler(inputCols=listcol,outputCol='features_modeling')\n",
        "df_pyspark=featureassembler.transform(df_pyspark)\n"
      ],
      "metadata": {
        "id": "uPAnVnkMkddU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data=df_pyspark.randomSplit([0.7,0.3])\n",
        "\n",
        "\n",
        "dt=DecisionTreeRegressor(featuresCol='features_modeling',labelCol='total_charge',\n",
        "                         maxDepth=5,minInstancesPerNode=round(df_pyspark.count()*0.01))\n",
        "model=dt.fit(train_data)\n",
        "\n",
        "predictions=model.transform(test_data)\n",
        "evaluator=RegressionEvaluator(labelCol='total_charge',predictionCol='prediction',metricName='mae')\n",
        "evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk-DLgbskxJU",
        "outputId": "3cb26c79-2c90-4017-8f2a-ac668d475d5c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.6142729908474713"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = predictions.select(\"total_charge\").toPandas()\n",
        "y_pred = predictions.select(\"prediction\").toPandas()\n",
        "\n",
        "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
        "print(f'r2_score: {r2_score:.3f}\\n')\n",
        "\n",
        "listcol=[x for x in df_pyspark.columns if re.compile('^.*_calls|mins$').search(x)]\n",
        "\n",
        "imp=model.featureImportances\n",
        "indices=np.argsort(imp)[::-1]\n",
        "sort_imp=sorted(imp,reverse=True)\n",
        "for name,value in zip(np.array(listcol)[indices],sort_imp):\n",
        "    print(name,':',f'{value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy0YhzTGk0l7",
        "outputId": "5de31c99-7a9a-40e9-d2e2-c574f75d36e7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2_score: 0.900\n",
            "\n",
            "day_mins : 0.8315\n",
            "evening_mins : 0.1636\n",
            "night_mins : 0.0049\n",
            "custserv_calls : 0.0000\n",
            "intl_calls : 0.0000\n",
            "intl_mins : 0.0000\n",
            "night_calls : 0.0000\n",
            "evening_calls : 0.0000\n",
            "day_calls : 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomForestRegressor**"
      ],
      "metadata": {
        "id": "6eaSEVYxk6BM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf=RandomForestRegressor(featuresCol='features_modeling',labelCol='total_charge',\n",
        "                         maxDepth=5,minInstancesPerNode=round(df_pyspark.count()*0.01))\n",
        "\n",
        "model=rf.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "\n",
        "evaluator=RegressionEvaluator(labelCol='total_charge',predictionCol=\"prediction\",metricName='mae')\n",
        "evaluator.evaluate(predictions)\n",
        "\n",
        "imp=model.featureImportances\n",
        "indices=np.argsort(imp)[::-1]\n",
        "sort_imp=sorted(imp,reverse=True)\n",
        "for name,value in zip(np.array(listcol)[indices],sort_imp):\n",
        "    print(name,':',f'{value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUZiuZ_OlAYU",
        "outputId": "3251da78-e312-4b20-c02b-fbd95b56c2f6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day_mins : 0.7737\n",
            "evening_mins : 0.1698\n",
            "night_mins : 0.0346\n",
            "day_charge : 0.0052\n",
            "intl_mins : 0.0051\n",
            "evening_charge : 0.0045\n",
            "night_charge : 0.0034\n",
            "intl_charge : 0.0025\n",
            "total_charge : 0.0012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GBTRegressor**"
      ],
      "metadata": {
        "id": "iXsTHoIip9nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf=GBTRegressor(featuresCol='features_modeling',labelCol='total_charge',\n",
        "                         maxDepth=5,minInstancesPerNode=round(df_pyspark.count()*0.01))\n",
        "model=rf.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "evaluator=RegressionEvaluator(labelCol='total_charge',predictionCol='prediction')\n",
        "evaluator.evaluate(predictions)\n",
        "\n",
        "imp=model.featureImportances\n",
        "indices=np.argsort(imp)[::-1]\n",
        "sort_imp=sorted(imp,reverse=True)\n",
        "for name,value in zip(np.array(listcol)[indices],sort_imp):\n",
        "    print(name,':',f'{value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TogQGmqjp8Kt",
        "outputId": "739d3e36-9932-4914-8899-43451cb7474f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day_mins : 0.5455\n",
            "night_mins : 0.2400\n",
            "evening_mins : 0.1658\n",
            "intl_mins : 0.0370\n",
            "night_charge : 0.0030\n",
            "evening_charge : 0.0024\n",
            "day_charge : 0.0023\n",
            "intl_charge : 0.0021\n",
            "total_charge : 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LogisticRegression"
      ],
      "metadata": {
        "id": "HN9IvJNusY9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listcol=[x for x in df_pyspark.columns if re.compile('^._calls|_mins|_charge').search(x)]\n",
        "featureassembler=VectorAssembler(inputCols=listcol,outputCol='features_clf')\n",
        "df_pyspark=featureassembler.transform(df_pyspark)\n",
        "df_pyspark=df_pyspark.withColumn('churn',f.when(f.col('churn').isin('TRUE'), 1).when(f.col('churn').isin('FALSE'), 0))"
      ],
      "metadata": {
        "id": "rBCCe6A7qVzt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logr=LogisticRegression(featuresCol='features_clf',labelCol='churn')\n",
        "(train_data,test_data)=df_pyspark.randomSplit([0.7,0.3],seed=42)\n",
        "model=logr.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "predictions.select('features_clf','churn','prediction').show()\n",
        "\n",
        "df_pyspark.groupBy('churn').count().withColumn('PRC_count',f.col('count')/df_pyspark.count()).show()\n",
        "\n",
        "\n",
        "\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol='churn',predictionCol='prediction',\n",
        "                                            metricName='accuracy')\n",
        "\n",
        "multiclass_metrics=['accuracy','weightedRecall','weightedPrecision','f1']\n",
        "for metric in multiclass_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName:metric})\n",
        "    print(f'Metrics {metric}: {result:.4f}')\n",
        "\n",
        "evaluator=BinaryClassificationEvaluator(labelCol='churn',rawPredictionCol='prediction')\n",
        "binary_metrics=['areaUnderROC','areaUnderPR']\n",
        "for metric in binary_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Binary {metric}: {result:.4f}')\n",
        "\n",
        "\n",
        "predictions.groupBy('prediction').count().withColumn('PRC',f.col('count')/predictions.count()).show()\n",
        "\n",
        "trainingSummary=model.summary\n",
        "trainingSummary.roc.show(5)\n",
        "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
        "fMeasure = trainingSummary.fMeasureByThreshold\n",
        "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head(5)\n",
        "print(maxFMeasure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTeLfqqzqMe2",
        "outputId": "ebb4993e-d009-4dad-ab06-bbc1c053ed39"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|        features_clf|churn|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|[159.3,27.08,125....|    0|       0.0|\n",
            "|[217.0,36.89,152....|    0|       0.0|\n",
            "|[148.3,25.21,181....|    0|       0.0|\n",
            "|[139.3,23.68,178....|    0|       0.0|\n",
            "|[252.4,42.91,187....|    0|       0.0|\n",
            "|[185.0,31.45,232....|    0|       0.0|\n",
            "|[262.3,44.59,198....|    0|       0.0|\n",
            "|[190.3,32.35,194....|    0|       0.0|\n",
            "|[150.0,25.5,159.4...|    0|       0.0|\n",
            "|[238.4,40.53,246....|    0|       0.0|\n",
            "|[213.6,36.31,175....|    0|       0.0|\n",
            "|[103.0,17.51,242....|    0|       0.0|\n",
            "|[100.1,17.02,233....|    0|       0.0|\n",
            "|[148.4,25.23,193....|    0|       0.0|\n",
            "|[245.2,41.68,159....|    0|       0.0|\n",
            "|[181.5,30.86,205....|    0|       0.0|\n",
            "|[178.4,30.33,168....|    0|       0.0|\n",
            "|[182.3,30.99,169....|    0|       0.0|\n",
            "|[175.7,29.87,187....|    0|       0.0|\n",
            "|[181.1,30.79,314....|    0|       0.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----+-----+-------------------+\n",
            "|churn|count|          PRC_count|\n",
            "+-----+-----+-------------------+\n",
            "|    1|  483|0.14491449144914492|\n",
            "|    0| 2850| 0.8550855085508551|\n",
            "+-----+-----+-------------------+\n",
            "\n",
            "Metrics accuracy: 0.8603\n",
            "Metrics weightedRecall: 0.8603\n",
            "Metrics weightedPrecision: 0.8799\n",
            "Metrics f1: 0.7997\n",
            "Binary areaUnderROC: 0.5147\n",
            "Binary areaUnderPR: 0.5845\n",
            "+----------+-----+--------------------+\n",
            "|prediction|count|                 PRC|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  941|  0.9957671957671957|\n",
            "|       1.0|    4|0.004232804232804233|\n",
            "+----------+-----+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|                 FPR|                 TPR|\n",
            "+--------------------+--------------------+\n",
            "|                 0.0|                 0.0|\n",
            "|                 0.0|0.005763688760806916|\n",
            "|                 0.0|0.011527377521613832|\n",
            "|                 0.0| 0.01729106628242075|\n",
            "|9.799118079372856E-4| 0.01729106628242075|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "areaUnderROC: 0.6539548760496283\n",
            "[Row(max(F-Measure)=0.49572649572649563)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DecisionTreeClassifier**"
      ],
      "metadata": {
        "id": "rWRPkw1Fs30v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtre=DecisionTreeClassifier(featuresCol='features_clf',labelCol='churn',\n",
        "                            maxDepth=5,minInstancesPerNode=round(df_pyspark.count()*0.01))\n",
        "model=dtre.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol='churn',predictionCol='prediction',metricName='accuracy')\n",
        "multiclass_metrics=['accuracy','weightedRecall','weightedPrecision','f1']\n",
        "\n",
        "for metric in multiclass_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Metric {metric}: {result}')\n",
        "\n",
        "evaluator=BinaryClassificationEvaluator(labelCol='churn',rawPredictionCol='prediction')\n",
        "binary_metrics=['areaUnderROC','areaUnderPR']\n",
        "print('\\n')\n",
        "for metric in binary_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Binary {metric}: {result:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVaFUvIzsq9G",
        "outputId": "c3669410-b912-438b-cae6-febb7734b6f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric accuracy: 0.8888888888888888\n",
            "Metric weightedRecall: 0.8888888888888888\n",
            "Metric weightedPrecision: 0.8763145861911293\n",
            "Metric f1: 0.8766343807509956\n",
            "\n",
            "\n",
            "Binary areaUnderROC: 0.6904\n",
            "Binary areaUnderPR: 0.5303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imp=model.featureImportances\n",
        "indices=np.argsort(imp)[::-1]\n",
        "sort_imp=sorted(imp,reverse=True)\n",
        "for name,value in zip(np.array(listcol)[indices],sort_imp):\n",
        "    print(name,':',f'{value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pw8SZf7s_f2",
        "outputId": "fbc091ad-7aaf-4454-f482-3fef3e786199"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_charge : 0.9937\n",
            "day_mins : 0.0063\n",
            "intl_charge : 0.0000\n",
            "intl_mins : 0.0000\n",
            "night_charge : 0.0000\n",
            "night_mins : 0.0000\n",
            "evening_charge : 0.0000\n",
            "evening_mins : 0.0000\n",
            "day_charge : 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomForestClassifier**"
      ],
      "metadata": {
        "id": "rMyw-1h0tuiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf=RandomForestClassifier(featuresCol='features_clf',labelCol='churn',\n",
        "                            maxDepth=5,minInstancesPerNode=round(df_pyspark.count()*0.01))\n",
        "model=rf.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol='churn',predictionCol='prediction',metricName='accuracy')\n",
        "multiclass_metrics=['accuracy','weightedRecall','weightedPrecision','f1']\n",
        "\n",
        "for metric in multiclass_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Metric {metric}: {result}')\n",
        "\n",
        "evaluator=BinaryClassificationEvaluator(labelCol='churn',rawPredictionCol='prediction')\n",
        "binary_metrics=['areaUnderROC','areaUnderPR']\n",
        "print('\\n')\n",
        "for metric in binary_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Binary {metric}: {result:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N1Xfs49tuGX",
        "outputId": "6eb71dc3-339d-49b5-e089-96b8b2ad840c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric accuracy: 0.8814814814814815\n",
            "Metric weightedRecall: 0.8814814814814815\n",
            "Metric weightedPrecision: 0.867886612869853\n",
            "Metric f1: 0.8570728232397171\n",
            "\n",
            "\n",
            "Binary areaUnderROC: 0.6280\n",
            "Binary areaUnderPR: 0.5230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imp=model.featureImportances\n",
        "indices=np.argsort(imp)[::-1]\n",
        "sort_imp=sorted(imp,reverse=True)\n",
        "for name,value in zip(np.array(listcol)[indices],sort_imp):\n",
        "    print(name,':',f'{value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-un0AxXt1l-",
        "outputId": "9df2c38b-46e4-4a91-8046-247047baca98"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_charge : 0.4161\n",
            "day_mins : 0.2906\n",
            "day_charge : 0.2030\n",
            "evening_mins : 0.0258\n",
            "evening_charge : 0.0237\n",
            "night_charge : 0.0189\n",
            "intl_charge : 0.0091\n",
            "intl_mins : 0.0073\n",
            "night_mins : 0.0055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GBTClassifier**"
      ],
      "metadata": {
        "id": "u6SIRZzpvAVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbt=GBTClassifier(featuresCol='features_clf',labelCol='churn',\n",
        "                            maxDepth=5,minInstancesPerNode=round(df_pyspark.count()*0.01))\n",
        "model=gbt.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol='churn',predictionCol='prediction',metricName='accuracy')\n",
        "multiclass_metrics=['accuracy','weightedRecall','weightedPrecision','f1']\n",
        "\n",
        "for metric in multiclass_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Metric {metric}: {result}')\n",
        "\n",
        "evaluator=BinaryClassificationEvaluator(labelCol='churn',rawPredictionCol='prediction')\n",
        "binary_metrics=['areaUnderROC','areaUnderPR']\n",
        "print('\\n')\n",
        "for metric in binary_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Binary {metric}: {result:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qQEM_VRupzX",
        "outputId": "931715b1-5d93-419d-bba2-b9d1f64b3399"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric accuracy: 0.8867724867724868\n",
            "Metric weightedRecall: 0.8867724867724868\n",
            "Metric weightedPrecision: 0.8731796335195858\n",
            "Metric f1: 0.8718288489477318\n",
            "\n",
            "\n",
            "Binary areaUnderROC: 0.6739\n",
            "Binary areaUnderPR: 0.5253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imp=model.featureImportances\n",
        "indices=np.argsort(imp)[::-1]\n",
        "sort_imp=sorted(imp,reverse=True)\n",
        "for name,value in zip(np.array(listcol)[indices],sort_imp):\n",
        "    print(name,':',f'{value:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za_v3dH7u9lh",
        "outputId": "64dcf268-c8ff-4813-8e2a-d177871aeae6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custserv_calls : 0.3488\n",
            "intl_mins : 0.2272\n",
            "evening_mins : 0.1438\n",
            "night_mins : 0.1208\n",
            "day_mins : 0.1024\n",
            "night_calls : 0.0413\n",
            "evening_calls : 0.0158\n",
            "intl_calls : 0.0000\n",
            "day_calls : 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive** **Bayes**"
      ],
      "metadata": {
        "id": "Uqiic37VvJuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb = NaiveBayes(featuresCol='features_clf', labelCol='churn')\n",
        "\n",
        "model=nb.fit(train_data)\n",
        "predictions=model.transform(test_data)\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol='churn',predictionCol='prediction',metricName='accuracy')\n",
        "multiclass_metrics=['accuracy','weightedRecall','weightedPrecision','f1']\n",
        "\n",
        "for metric in multiclass_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Metric {metric}: {result}')\n",
        "\n",
        "evaluator=BinaryClassificationEvaluator(labelCol='churn',rawPredictionCol='prediction')\n",
        "binary_metrics=['areaUnderROC','areaUnderPR']\n",
        "print('\\n')\n",
        "for metric in binary_metrics:\n",
        "    result=evaluator.evaluate(predictions,{evaluator.metricName: metric})\n",
        "    print(f'Binary {metric}: {result:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaKY5TxPvFao",
        "outputId": "c44e2d22-1006-45f3-a94e-22cb76df4105"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric accuracy: 0.6634920634920635\n",
            "Metric weightedRecall: 0.6634920634920635\n",
            "Metric weightedPrecision: 0.7966778439107283\n",
            "Metric f1: 0.7099680611268521\n",
            "\n",
            "\n",
            "Binary areaUnderROC: 0.6016\n",
            "Binary areaUnderPR: 0.1996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Means**"
      ],
      "metadata": {
        "id": "_6MaJAuFvgYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col=[item[0] for item in df_pyspark.dtypes if not(item[1].startswith('string'))]\n",
        "\n",
        "featureassembler=VectorAssembler(inputCols=col,outputCol='features_clust')\n",
        "df_pyspark=featureassembler.transform(df_pyspark)\n",
        "sil=[]\n",
        "for k in range(5,10):\n",
        "    kmeans=KMeans().setK(k).setSeed(42).setFeaturesCol('features_clust').setPredictionCol('cluster')\n",
        "    model=kmeans.fit(df_pyspark)\n",
        "    predictions=model.transform(df_pyspark)\n",
        "    evaluator=ClusteringEvaluator(featuresCol='features_clust',predictionCol='cluster')\n",
        "    silhouette=evaluator.evaluate(predictions)\n",
        "    sil.append(silhouette)"
      ],
      "metadata": {
        "id": "K8G060nkvfTZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7V63eD6vnK4",
        "outputId": "01ba74e2-4fc7-41cb-9e01-5c0f5c1879c3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2548164267567587, 0.24565456894744797, 0.24805341316205598, 0.23715204757475922, 0.23605261908185068]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Mixture Model**"
      ],
      "metadata": {
        "id": "ZhvJow7nvrQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sil=[]\n",
        "for k in range(5, 10):\n",
        "    gmm = GaussianMixture(k=k, seed=42, featuresCol='features_clust', predictionCol='cluster')\n",
        "    model = gmm.fit(df_pyspark)\n",
        "    predictions = model.transform(df_pyspark)\n",
        "    evaluator = ClusteringEvaluator(featuresCol='features_clust', predictionCol='cluster')\n",
        "    silhouette = evaluator.evaluate(predictions)\n",
        "    sil.append(silhouette)\n",
        "\n",
        "print(sil)"
      ],
      "metadata": {
        "id": "9GvBc3Jiv4Ah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}